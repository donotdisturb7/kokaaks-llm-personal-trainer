#!/usr/bin/env python3
"""
Script de test pour v√©rifier la connexion Ollama
Teste la connectivit√© et les fonctionnalit√©s de base
"""
import asyncio
import sys
import os

# Ajouter le dossier app au path
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from app.config import get_settings
from app.services.ollama_service import create_ollama_service


async def test_ollama_connection():
    """Test de connexion √† Ollama"""
    print("üîç Test de connexion Ollama...")
    print("=" * 50)
    
    settings = get_settings()
    print(f"üìç Configuration Ollama:")
    print(f"   Host: {settings.ollama_host}")
    print(f"   Port: {settings.ollama_port}")
    print(f"   Mod√®le: {settings.ollama_model}")
    print(f"   URL: {settings.ollama_base_url}")
    print()
    
    try:
        async with create_ollama_service(settings) as ollama:
            # Test 1: Health check
            print("1Ô∏è‚É£ Test de sant√© (health check)...")
            is_healthy = await ollama.health_check()
            if is_healthy:
                print("   ‚úÖ Ollama est accessible")
            else:
                print("   ‚ùå Ollama n'est pas accessible")
                return False
            print()
            
            # Test 2: Liste des mod√®les
            print("2Ô∏è‚É£ R√©cup√©ration des mod√®les disponibles...")
            models = await ollama.get_available_models()
            if models:
                print(f"   ‚úÖ {len(models)} mod√®le(s) trouv√©(s):")
                for model in models:
                    print(f"      - {model}")
            else:
                print("   ‚ö†Ô∏è  Aucun mod√®le trouv√©")
            print()
            
            # Test 3: G√©n√©ration de texte simple
            print("3Ô∏è‚É£ Test de g√©n√©ration de texte...")
            test_prompt = "Dis bonjour en fran√ßais"
            response = await ollama.generate_response(test_prompt)
            if response:
                print(f"   ‚úÖ R√©ponse g√©n√©r√©e:")
                print(f"      Prompt: {test_prompt}")
                print(f"      R√©ponse: {response[:100]}...")
            else:
                print("   ‚ùå Aucune r√©ponse g√©n√©r√©e")
            print()
            
            # Test 4: G√©n√©ration sp√©cialis√©e aim training
            print("4Ô∏è‚É£ Test de g√©n√©ration sp√©cialis√©e (aim training)...")
            aim_prompt = "Comment am√©liorer mon tracking dans KovaaK's ?"
            aim_response = await ollama.generate_aim_training_advice(aim_prompt)
            if aim_response:
                print(f"   ‚úÖ Conseil d'entra√Ænement g√©n√©r√©:")
                print(f"      Question: {aim_prompt}")
                print(f"      R√©ponse: {aim_response[:150]}...")
            else:
                print("   ‚ùå Aucun conseil g√©n√©r√©")
            print()
            
            print("üéâ Tous les tests sont pass√©s avec succ√®s !")
            return True
            
    except Exception as e:
        print(f"‚ùå Erreur lors des tests: {e}")
        return False


async def main():
    """Fonction principale"""
    print("ü§ñ Test de connexion Ollama pour KovaaK's AI Personal Trainer")
    print("=" * 70)
    print()
    
    success = await test_ollama_connection()
    
    print()
    print("=" * 70)
    if success:
        print("‚úÖ Connexion Ollama fonctionnelle !")
        print("üöÄ Vous pouvez maintenant d√©marrer l'API avec: python run.py")
    else:
        print("‚ùå Probl√®me de connexion Ollama")
        print("üí° V√©rifiez que:")
        print("   - Ollama est install√© et d√©marr√©")
        print("   - Le mod√®le est t√©l√©charg√©")
        print("   - Les param√®tres de connexion sont corrects")
        print("   - Le fichier .env est configur√©")
    
    return success


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
